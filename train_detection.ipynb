{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Project Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/opt/homebrew/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# select a TensorFlow 2 detection model for use\n",
    "# this is customizable - select a model here: https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_detection_zoo.md\n",
    "CUSTOM_MODEL_NAME = 'my_ssd_resnet50' \n",
    "PRETRAINED_MODEL_NAME = 'ssd_resnet50_v1_fpn_640x640_coco17_tpu-8'\n",
    "PRETRAINED_MODEL_URL = 'http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_resnet50_v1_fpn_640x640_coco17_tpu-8.tar.gz'\n",
    "TF_RECORD_SCRIPT_NAME = 'generate_tfrecord.py'\n",
    "LABEL_MAP_NAME = 'label_map.pbtxt'\n",
    "\n",
    "# set references to paths & files\n",
    "paths = {\n",
    "\t'assets_PATH': os.path.join('Tensorflow', 'assets'),   # assets directory, contains everything for the project\n",
    "\t'SCRIPTS_PATH': os.path.join('Tensorflow','scripts'),\n",
    "\t'APIMODEL_PATH': os.path.join('Tensorflow','models'),\n",
    "\t'ANNOTATION_PATH': os.path.join('Tensorflow', 'assets','annotations'),\n",
    "\t'IMAGE_PATH': os.path.join('Tensorflow', 'assets','images'),\n",
    "\t'MODEL_PATH': os.path.join('Tensorflow', 'assets','models'), \t# contains the model imported above\n",
    "\t'PRETRAINED_MODEL_PATH': os.path.join('Tensorflow', 'assets','pre-trained-models'),\n",
    "\t'CHECKPOINT_PATH': os.path.join('Tensorflow', 'assets','models',CUSTOM_MODEL_NAME), \n",
    "\t'OUTPUT_PATH': os.path.join('Tensorflow', 'assets','models',CUSTOM_MODEL_NAME, 'export'), \n",
    "\t'TFJS_PATH':os.path.join('Tensorflow', 'assets','models',CUSTOM_MODEL_NAME, 'tfjsexport'), \n",
    "\t'TFLITE_PATH':os.path.join('Tensorflow', 'assets','models',CUSTOM_MODEL_NAME, 'tfliteexport'), \n",
    "\t'PROTOC_PATH':os.path.join('Tensorflow','protoc')\n",
    "}\n",
    "\n",
    "files = {\n",
    "\t'PIPELINE_CONFIG':os.path.join('Tensorflow', 'assets','models', CUSTOM_MODEL_NAME, 'pipeline.config'),\n",
    "\t'TF_RECORD_SCRIPT': os.path.join(paths['SCRIPTS_PATH'], TF_RECORD_SCRIPT_NAME), \n",
    "\t'LABELMAP': os.path.join(paths['ANNOTATION_PATH'], LABEL_MAP_NAME)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in paths.values():\n",
    "\tif not os.path.exists(path):\n",
    "\t\tif os.name == 'posix': # linux\n",
    "\t\t\t%mkdir -p {path}\n",
    "\t\tif os.name == 'nt': # windows \n",
    "\t\t\t%mkdir {path}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Download Model from TF2 Model Zoo & Install TFOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in ./gesture-detector/lib/python3.12/site-packages (3.8.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./gesture-detector/lib/python3.12/site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in ./gesture-detector/lib/python3.12/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./gesture-detector/lib/python3.12/site-packages (from matplotlib) (4.49.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./gesture-detector/lib/python3.12/site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: numpy<2,>=1.21 in ./gesture-detector/lib/python3.12/site-packages (from matplotlib) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in ./gesture-detector/lib/python3.12/site-packages (from matplotlib) (24.0)\n",
      "Requirement already satisfied: pillow>=8 in ./gesture-detector/lib/python3.12/site-packages (from matplotlib) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./gesture-detector/lib/python3.12/site-packages (from matplotlib) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./gesture-detector/lib/python3.12/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in ./gesture-detector/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: wget in ./gesture-detector/lib/python3.12/site-packages (3.2)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install matplotlib\n",
    "!pip3 install wget\n",
    "import wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'Tensorflow/models'...\n",
      "remote: Enumerating objects: 96640, done.\u001b[K\n",
      "remote: Counting objects: 100% (6529/6529), done.\u001b[K\n",
      "remote: Compressing objects: 100% (3523/3523), done.\u001b[K\n",
      "error: RPC failed; curl 18 HTTP/2 stream 5 was reset80.00 KiB/s\n",
      "error: 15947 bytes of body are still expected\n",
      "fetch-pack: unexpected disconnect while reading sideband packet\n",
      "fatal: early EOF\n",
      "fatal: fetch-pack: invalid index-pack output\n"
     ]
    }
   ],
   "source": [
    "# install current version of tensorflow-models to APIMODEL_PATH\n",
    "if not os.path.exists(os.path.join(paths['APIMODEL_PATH'], 'research','object_detection')):\n",
    "  !git clone https://github.com/tensorflow/models {paths['APIMODEL_PATH']}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWarning:\u001b[0m protobuf-c 1.5.0_2 is already installed and up-to-date.\n",
      "To reinstall 1.5.0_2, run:\n",
      "  brew reinstall protobuf-c\n",
      "object_detection/protos/anchor_generator.proto: line 1: syntax: command not found\n",
      "object_detection/protos/anchor_generator.proto: line 3: package: command not found\n",
      "object_detection/protos/anchor_generator.proto: line 5: import: command not found\n",
      "object_detection/protos/anchor_generator.proto: line 6: import: command not found\n",
      "object_detection/protos/anchor_generator.proto: line 7: import: command not found\n",
      "object_detection/protos/anchor_generator.proto: line 8: import: command not found\n",
      "object_detection/protos/anchor_generator.proto: line 10: //: is a directory\n",
      "object_detection/protos/anchor_generator.proto: line 11: //: is a directory\n",
      "object_detection/protos/anchor_generator.proto: line 12: message: command not found\n",
      "object_detection/protos/anchor_generator.proto: line 13: oneof: command not found\n",
      "object_detection/protos/anchor_generator.proto: line 14: GridAnchorGenerator: command not found\n",
      "object_detection/protos/anchor_generator.proto: line 15: SsdAnchorGenerator: command not found\n",
      "object_detection/protos/anchor_generator.proto: line 16: MultiscaleAnchorGenerator: command not found\n",
      "object_detection/protos/anchor_generator.proto: line 17: FlexibleGridAnchorGenerator: command not found\n",
      "object_detection/protos/anchor_generator.proto: line 18: syntax error near unexpected token `}'\n",
      "object_detection/protos/anchor_generator.proto: line 18: `  }'\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/bks/Documents/Side Projects/gesture-detector/Tensorflow/models/research/object_detection/builders/model_builder_tf2_test.py\", line 24, in <module>\n",
      "    from object_detection.builders import model_builder\n",
      "  File \"/Users/bks/Documents/Side Projects/gesture-detector/gesture-detector/lib/python3.12/site-packages/object_detection/builders/model_builder.py\", line 20, in <module>\n",
      "    from object_detection.builders import anchor_generator_builder\n",
      "  File \"/Users/bks/Documents/Side Projects/gesture-detector/gesture-detector/lib/python3.12/site-packages/object_detection/builders/anchor_generator_builder.py\", line 21, in <module>\n",
      "    from object_detection.protos import anchor_generator_pb2\n",
      "ImportError: cannot import name 'anchor_generator_pb2' from 'object_detection.protos' (/Users/bks/Documents/Side Projects/gesture-detector/gesture-detector/lib/python3.12/site-packages/object_detection/protos/__init__.py)\n"
     ]
    }
   ],
   "source": [
    "# install Protocal Buffer & TensorFlow Object Detection API\n",
    "if os.name=='posix':  # linux\n",
    "\t!brew install protobuf-c\n",
    "\t!cd Tensorflow/models/research && object_detection/protos/*.proto --python_out=. && pip install . && export PYTHONPATH=$PYTHONPATH:`pwd`:`pwd`/slim && cp object_detection/packages/tf2/setup.py . && python -m pip install . \n",
    "if os.name=='nt': # windows\n",
    "    wget.download(\"https://github.com/protocolbuffers/protobuf/releases/download/v3.15.6/protoc-3.15.6-win64.zip\")\n",
    "    %move protoc-3.15.6-win64.zip {paths['PROTOC_PATH']}\n",
    "    %cd {paths['PROTOC_PATH']} && tar -xf protoc-3.15.6-win64.zip\n",
    "    os.environ['PATH'] += os.pathsep + os.path.abspath(os.path.join(paths['PROTOC_PATH'], 'bin'))   \n",
    "    %cd Tensorflow/models/research && protoc object_detection/protos/*.proto --python_out=. && copy object_detection\\\\packages\\\\tf2\\\\setup.py setup.py && python setup.py build && python setup.py install\n",
    "    %cd Tensorflow/models/research/slim && pip install -e . \n",
    "   \n",
    "# verify installation \n",
    "VERIFICATION_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'builders', 'model_builder_tf2_test.py')\n",
    "!python {VERIFICATION_SCRIPT}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Could not find a version that satisfies the requirement tensorflow-metal (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for tensorflow-metal\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# for Apple Silicon: install tensorflow-metal for GPU use\n",
    "!pip3 install tensorflow-metal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWarning:\u001b[0m wget 1.21.4 is already installed and up-to-date.\n",
      "To reinstall 1.21.4, run:\n",
      "  brew reinstall wget\n",
      "--2024-03-10 12:15:09--  http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_resnet50_v1_fpn_640x640_coco17_tpu-8.tar.gz\n",
      "Resolving download.tensorflow.org (download.tensorflow.org)... 2607:f8b0:400b:803::201b, 2607:f8b0:400b:80c::201b, 2607:f8b0:400b:804::201b, ...\n",
      "Connecting to download.tensorflow.org (download.tensorflow.org)|2607:f8b0:400b:803::201b|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 244817203 (233M) [application/x-tar]\n",
      "Saving to: ‘ssd_resnet50_v1_fpn_640x640_coco17_tpu-8.tar.gz’\n",
      "\n",
      "ssd_resnet50_v1_fpn 100%[===================>] 233.48M  18.8MB/s    in 10s     \n",
      "\n",
      "2024-03-10 12:15:20 (22.8 MB/s) - ‘ssd_resnet50_v1_fpn_640x640_coco17_tpu-8.tar.gz’ saved [244817203/244817203]\n",
      "\n",
      "x ssd_resnet50_v1_fpn_640x640_coco17_tpu-8/\n",
      "x ssd_resnet50_v1_fpn_640x640_coco17_tpu-8/checkpoint/\n",
      "x ssd_resnet50_v1_fpn_640x640_coco17_tpu-8/checkpoint/ckpt-0.data-00000-of-00001\n",
      "x ssd_resnet50_v1_fpn_640x640_coco17_tpu-8/checkpoint/checkpoint\n",
      "x ssd_resnet50_v1_fpn_640x640_coco17_tpu-8/checkpoint/ckpt-0.index\n",
      "x ssd_resnet50_v1_fpn_640x640_coco17_tpu-8/pipeline.config\n",
      "x ssd_resnet50_v1_fpn_640x640_coco17_tpu-8/saved_model/\n",
      "x ssd_resnet50_v1_fpn_640x640_coco17_tpu-8/saved_model/saved_model.pb\n",
      "x ssd_resnet50_v1_fpn_640x640_coco17_tpu-8/saved_model/assets/\n",
      "x ssd_resnet50_v1_fpn_640x640_coco17_tpu-8/saved_model/variables/\n",
      "x ssd_resnet50_v1_fpn_640x640_coco17_tpu-8/saved_model/variables/variables.data-00000-of-00001\n",
      "x ssd_resnet50_v1_fpn_640x640_coco17_tpu-8/saved_model/variables/variables.index\n"
     ]
    }
   ],
   "source": [
    "import object_detection\n",
    "# pre-trained models to be leveraged\n",
    "if os.name =='posix': # linux\n",
    "\t!brew install wget\n",
    "\t!wget {PRETRAINED_MODEL_URL}\n",
    "\t!mv {PRETRAINED_MODEL_NAME+'.tar.gz'} {paths['PRETRAINED_MODEL_PATH']}\n",
    "\t!cd {paths['PRETRAINED_MODEL_PATH']} && tar -zxvf {PRETRAINED_MODEL_NAME+'.tar.gz'}\n",
    "if os.name == 'nt': # windows\n",
    "\twget.download(PRETRAINED_MODEL_URL)\n",
    "\t!move {PRETRAINED_MODEL_NAME+'.tar.gz'} {paths['PRETRAINED_MODEL_PATH']}\n",
    "\t!cd {paths['PRETRAINED_MODEL_PATH']} && tar -zxvf {PRETRAINED_MODEL_NAME+'.tar.gz'}\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Create Label Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [{'name':'ThumbsUp', 'id':1}, {'name':'ThumbsDown', 'id':2}, {'name':'Up', 'id':3}, {'name':'Down', 'id':4},{'name':'Left', 'id':5}, {'name':'Right', 'id':6}]\n",
    "\n",
    "with open(files['LABELMAP'], 'w') as f:\n",
    "\tfor label in labels:\n",
    "\t\tf.write('item { \\n')\n",
    "\t\tf.write('\\tname:\\'{}\\'\\n'.format(label['name']))\n",
    "\t\tf.write('\\tid:{}\\n'.format(label['id']))\n",
    "\t\tf.write('}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Generate TF Records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'Tensorflow/scripts'...\n",
      "remote: Enumerating objects: 3, done.\u001b[K\n",
      "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
      "remote: Compressing objects: 100% (2/2), done.\u001b[K\n",
      "remote: Total 3 (delta 0), reused 1 (delta 0), pack-reused 0\u001b[K\n",
      "Receiving objects: 100% (3/3), done.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/bks/Documents/Side Projects/gesture-detector/Tensorflow/scripts/generate_tfrecord.py\", line 29, in <module>\n",
      "    from object_detection.utils import dataset_util, label_map_util\n",
      "  File \"/Users/bks/Documents/Side Projects/gesture-detector/gesture-detector/lib/python3.12/site-packages/object_detection/utils/label_map_util.py\", line 21, in <module>\n",
      "    from object_detection.protos import string_int_label_map_pb2\n",
      "ImportError: cannot import name 'string_int_label_map_pb2' from 'object_detection.protos' (/Users/bks/Documents/Side Projects/gesture-detector/gesture-detector/lib/python3.12/site-packages/object_detection/protos/__init__.py)\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/bks/Documents/Side Projects/gesture-detector/Tensorflow/scripts/generate_tfrecord.py\", line 29, in <module>\n",
      "    from object_detection.utils import dataset_util, label_map_util\n",
      "  File \"/Users/bks/Documents/Side Projects/gesture-detector/gesture-detector/lib/python3.12/site-packages/object_detection/utils/label_map_util.py\", line 21, in <module>\n",
      "    from object_detection.protos import string_int_label_map_pb2\n",
      "ImportError: cannot import name 'string_int_label_map_pb2' from 'object_detection.protos' (/Users/bks/Documents/Side Projects/gesture-detector/gesture-detector/lib/python3.12/site-packages/object_detection/protos/__init__.py)\n"
     ]
    }
   ],
   "source": [
    "# use a TFRecord generator script by developer nicknochnack\n",
    "if not os.path.exists(files['TF_RECORD_SCRIPT']):\n",
    "  !git clone https://github.com/nicknochnack/GenerateTFRecord {paths['SCRIPTS_PATH']}\n",
    "!python {files['TF_RECORD_SCRIPT']} -x {os.path.join(paths['IMAGE_PATH'], 'train')} -l {files['LABELMAP']} -o {os.path.join(paths['ANNOTATION_PATH'], 'train.record')} \n",
    "!python {files['TF_RECORD_SCRIPT']} -x {os.path.join(paths['IMAGE_PATH'], 'test')} -l {files['LABELMAP']} -o {os.path.join(paths['ANNOTATION_PATH'], 'test.record')} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Copy Model Config Files to Training Folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.name =='posix': # linux\n",
    "\t!cp {os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'pipeline.config')} {os.path.join(paths['CHECKPOINT_PATH'])}\n",
    "if os.name == 'nt': # windows\n",
    "\t!copy {os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'pipeline.config')} {os.path.join(paths['CHECKPOINT_PATH'])}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Update Config Files for Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'eval_pb2' from 'object_detection.protos' (/Users/bks/Documents/Side Projects/gesture-detector/gesture-detector/lib/python3.12/site-packages/object_detection/protos/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mobject_detection\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m config_util\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mobject_detection\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotos\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pipeline_pb2\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m text_format\n",
      "File \u001b[0;32m~/Documents/Side Projects/gesture-detector/gesture-detector/lib/python3.12/site-packages/object_detection/utils/config_util.py:24\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m text_format\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m file_io\n\u001b[0;32m---> 24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mobject_detection\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotos\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m eval_pb2\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mobject_detection\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotos\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m graph_rewriter_pb2\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mobject_detection\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotos\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m input_reader_pb2\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'eval_pb2' from 'object_detection.protos' (/Users/bks/Documents/Side Projects/gesture-detector/gesture-detector/lib/python3.12/site-packages/object_detection/protos/__init__.py)"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from object_detection.utils import config_util\n",
    "from object_detection.protos import pipeline_pb2\n",
    "from google.protobuf import text_format\n",
    "\n",
    "config = config_util.get_configs_from_pipeline_file(files['PIPELINE_CONFIG'])\n",
    "config\n",
    "pipeline_config = pipeline_pb2.TrainEvalPipelineConfig()\n",
    "with tf.io.gfile.GFile(files['PIPELINE_CONFIG'], \"r\") as f:\n",
    "  proto_str = f.read()  \n",
    "  text_format.Merge(proto_str, pipeline_config)\n",
    "pipeline_config.model.ssd.num_classes = len(labels)\n",
    "pipeline_config.train_config.batch_size = 4\n",
    "pipeline_config.train_config.fine_tune_checkpoint = os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'checkpoint', 'ckpt-0')\n",
    "pipeline_config.train_config.fine_tune_checkpoint_type = \"detection\"\n",
    "pipeline_config.train_input_reader.label_map_path= files['LABELMAP']\n",
    "pipeline_config.train_input_reader.tf_record_input_reader.input_path[:] = [os.path.join(paths['ANNOTATION_PATH'], 'train.record')]\n",
    "pipeline_config.eval_input_reader[0].label_map_path = files['LABELMAP']\n",
    "pipeline_config.eval_input_reader[0].tf_record_input_reader.input_path[:] = [os.path.join(paths['ANNOTATION_PATH'], 'test.record')]\n",
    "config_text = text_format.MessageToString(pipeline_config)\n",
    "with tf.io.gfile.GFile(files['PIPELINE_CONFIG'], \"wb\") as f:\n",
    "  f.write(config_text)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Train & Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python Tensorflow/models/research/object_detection/model_main_tf2.py --model_dir=Tensorflow/assets/models/my_ssd_resnet50 --pipeline_config_path=Tensorflow/assets/models/my_ssd_resnet50/pipeline.config --num_train_steps=10000\n",
      "/opt/homebrew/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/Resources/Python.app/Contents/MacOS/Python: can't open file '/Users/bks/Documents/Side Projects/gesture-detector/Tensorflow/models/research/object_detection/model_main_tf2.py': [Errno 2] No such file or directory\n",
      "python Tensorflow/models/research/object_detection/model_main_tf2.py --model_dir=Tensorflow/assets/models/my_ssd_resnet50 --pipeline_config_path=Tensorflow/assets/models/my_ssd_resnet50/pipeline.config --checkpoint_dir=Tensorflow/assets/models/my_ssd_resnet50\n",
      "/opt/homebrew/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/Resources/Python.app/Contents/MacOS/Python: can't open file '/Users/bks/Documents/Side Projects/gesture-detector/Tensorflow/models/research/object_detection/model_main_tf2.py': [Errno 2] No such file or directory\n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "TRAINING_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'model_main_tf2.py')\n",
    "command = \"python {} --model_dir={} --pipeline_config_path={} --num_train_steps=10000\".format(TRAINING_SCRIPT, paths['CHECKPOINT_PATH'],files['PIPELINE_CONFIG'])\n",
    "print(command)\n",
    "!{command}\n",
    "\n",
    "# evaluate the model\n",
    "command = \"python {} --model_dir={} --pipeline_config_path={} --checkpoint_dir={}\".format(TRAINING_SCRIPT, paths['CHECKPOINT_PATH'],files['PIPELINE_CONFIG'], paths['CHECKPOINT_PATH'])\n",
    "print(command)\n",
    "!{command}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Load Train Model From Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'string_int_label_map_pb2' from 'object_detection.protos' (/Users/bks/Documents/Side Projects/gesture-detector/gesture-detector/lib/python3.12/site-packages/object_detection/protos/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mobject_detection\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m label_map_util\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mobject_detection\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m visualization_utils \u001b[38;5;28;01mas\u001b[39;00m viz_utils\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mobject_detection\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbuilders\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m model_builder\n",
      "File \u001b[0;32m~/Documents/Side Projects/gesture-detector/gesture-detector/lib/python3.12/site-packages/object_detection/utils/label_map_util.py:21\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m text_format\n\u001b[0;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mobject_detection\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotos\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m string_int_label_map_pb2\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_validate_label_map\u001b[39m(label_map):\n\u001b[1;32m     25\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Checks if a label map is valid.\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \n\u001b[1;32m     27\u001b[0m \u001b[38;5;124;03m  Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;124;03m    ValueError: if label map is invalid.\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'string_int_label_map_pb2' from 'object_detection.protos' (/Users/bks/Documents/Side Projects/gesture-detector/gesture-detector/lib/python3.12/site-packages/object_detection/protos/__init__.py)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import visualization_utils as viz_utils\n",
    "from object_detection.builders import model_builder\n",
    "from object_detection.utils import config_util\n",
    "\n",
    "# Load pipeline config and build a detection model\n",
    "configs = config_util.get_configs_from_pipeline_file(files['PIPELINE_CONFIG'])\n",
    "detection_model = model_builder.build(model_config=configs['model'], is_training=False)\n",
    "\n",
    "# Restore checkpoint\n",
    "ckpt = tf.compat.v2.train.Checkpoint(model=detection_model)\n",
    "ckpt.restore(os.path.join(paths['CHECKPOINT_PATH'], 'ckpt-1')).expect_partial()\n",
    "\n",
    "@tf.function\n",
    "def detect_fn(image):\n",
    "\timage, shapes = detection_model.preprocess(image)\n",
    "\tprediction_dict = detection_model.predict(image, shapes)\n",
    "\tdetections = detection_model.postprocess(prediction_dict, shapes)\n",
    "\treturn detections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Detect from an Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m \n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pyplot \u001b[38;5;28;01mas\u001b[39;00m plt\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "import cv2 \n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# detect objects from an image\n",
    "# edit the image filename below\n",
    "\n",
    "category_index = label_map_util.create_category_index_from_labelmap(files['LABELMAP'])\n",
    "IMAGE_PATH = os.path.join(paths['IMAGE_PATH'], 'test', 'IMAGEPATH.jpg')\n",
    "img = cv2.imread(IMAGE_PATH)\n",
    "image_np = np.array(img)\n",
    "\n",
    "input_tensor = tf.convert_to_tensor(np.expand_dims(image_np, 0), dtype=tf.float32)\n",
    "detections = detect_fn(input_tensor)\n",
    "\n",
    "num_detections = int(detections.pop('num_detections'))\n",
    "detections = {key: value[0, :num_detections].numpy()\n",
    "              for key, value in detections.items()}\n",
    "detections['num_detections'] = num_detections\n",
    "\n",
    "# detection_classes should be ints.\n",
    "detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
    "\n",
    "label_id_offset = 1\n",
    "image_np_with_detections = image_np.copy()\n",
    "\n",
    "viz_utils.visualize_boxes_and_labels_on_image_array(\n",
    "            image_np_with_detections,\n",
    "            detections['detection_boxes'],\n",
    "            detections['detection_classes']+label_id_offset,\n",
    "            detections['detection_scores'],\n",
    "            category_index,\n",
    "            use_normalized_coordinates=True,\n",
    "            max_boxes_to_draw=5,\n",
    "            min_score_thresh=.8,\n",
    "            agnostic_mode=False)\n",
    "\n",
    "plt.imshow(cv2.cvtColor(image_np_with_detections, cv2.COLOR_BGR2RGB))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Real-Time Detections from Webcam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cv2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m cap \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241m.\u001b[39mVideoCapture(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m      2\u001b[0m width \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(cap\u001b[38;5;241m.\u001b[39mget(cv2\u001b[38;5;241m.\u001b[39mCAP_PROP_FRAME_WIDTH))\n\u001b[1;32m      3\u001b[0m height \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(cap\u001b[38;5;241m.\u001b[39mget(cv2\u001b[38;5;241m.\u001b[39mCAP_PROP_FRAME_HEIGHT))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cv2' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "while cap.isOpened(): \n",
    "\tret, frame = cap.read()\n",
    "\timage_np = np.array(frame)\n",
    "    \n",
    "\tinput_tensor = tf.convert_to_tensor(np.expand_dims(image_np, 0), dtype=tf.float32)\n",
    "\tdetections = detect_fn(input_tensor)\n",
    "\t\n",
    "\tnum_detections = int(detections.pop('num_detections'))\n",
    "\tdetections = {key: value[0, :num_detections].numpy()\n",
    "\t\t\t\t\t\t\t\tfor key, value in detections.items()}\n",
    "\tdetections['num_detections'] = num_detections\n",
    "\n",
    "\t# detection_classes should be ints.\n",
    "\tdetections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
    "\n",
    "\tlabel_id_offset = 1\n",
    "\timage_np_with_detections = image_np.copy()\n",
    "\n",
    "\tviz_utils.visualize_boxes_and_labels_on_image_array(\n",
    "\t\timage_np_with_detections,\n",
    "\t\tdetections['detection_boxes'],\n",
    "\t\tdetections['detection_classes']+label_id_offset,\n",
    "\t\tdetections['detection_scores'],\n",
    "\t\tcategory_index,\n",
    "\t\tuse_normalized_coordinates=True,\n",
    "\t\tmax_boxes_to_draw=5,\n",
    "\t\tmin_score_thresh=.8,\n",
    "\t\tagnostic_mode=False)\n",
    "\n",
    "\tcv2.imshow('object detection',  cv2.resize(image_np_with_detections, (800, 600)))\n",
    "\t\n",
    "\tif cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "\t\tcap.release()\n",
    "\t\tcv2.destroyAllWindows()\n",
    "\t\tbreak"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Saving the Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python Tensorflow/models/research/object_detection/exporter_main_v2.py  --input_type=image_tensor --pipeline_config_path=Tensorflow/assets/models/my_ssd_resnet50/pipeline.config --trained_checkpoint_dir=Tensorflow/assets/models/my_ssd_resnet50 --output_directory=Tensorflow/assets/models/my_ssd_resnet50/export\n"
     ]
    }
   ],
   "source": [
    "# save model for future use\n",
    "FREEZE_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'exporter_main_v2.py ')\n",
    "command = \"python {} --input_type=image_tensor --pipeline_config_path={} --trained_checkpoint_dir={} --output_directory={}\".format(FREEZE_SCRIPT ,files['PIPELINE_CONFIG'], paths['CHECKPOINT_PATH'], paths['OUTPUT_PATH'])\n",
    "print(command)\n",
    "!{command}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11. Convert to TensorFlowJS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflowjs in /Users/bks/Library/CloudStorage/OneDrive-UniversityofWaterloo/Side Projects/object-detector/obj-detector/lib/python3.12/site-packages (3.18.0)\n",
      "Requirement already satisfied: tensorflow<3,>=2.1.0 in /Users/bks/Library/CloudStorage/OneDrive-UniversityofWaterloo/Side Projects/object-detector/obj-detector/lib/python3.12/site-packages (from tensorflowjs) (2.16.1)\n",
      "Requirement already satisfied: six<2,>=1.12.0 in /Users/bks/Library/CloudStorage/OneDrive-UniversityofWaterloo/Side Projects/object-detector/obj-detector/lib/python3.12/site-packages (from tensorflowjs) (1.16.0)\n",
      "Requirement already satisfied: tensorflow-hub<0.13,>=0.7.0 in /Users/bks/Library/CloudStorage/OneDrive-UniversityofWaterloo/Side Projects/object-detector/obj-detector/lib/python3.12/site-packages (from tensorflowjs) (0.12.0)\n",
      "Requirement already satisfied: packaging~=20.9 in /Users/bks/Library/CloudStorage/OneDrive-UniversityofWaterloo/Side Projects/object-detector/obj-detector/lib/python3.12/site-packages (from tensorflowjs) (20.9)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /Users/bks/Library/CloudStorage/OneDrive-UniversityofWaterloo/Side Projects/object-detector/obj-detector/lib/python3.12/site-packages (from packaging~=20.9->tensorflowjs) (3.1.2)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /Users/bks/Library/CloudStorage/OneDrive-UniversityofWaterloo/Side Projects/object-detector/obj-detector/lib/python3.12/site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /Users/bks/Library/CloudStorage/OneDrive-UniversityofWaterloo/Side Projects/object-detector/obj-detector/lib/python3.12/site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /Users/bks/Library/CloudStorage/OneDrive-UniversityofWaterloo/Side Projects/object-detector/obj-detector/lib/python3.12/site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (24.3.7)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /Users/bks/Library/CloudStorage/OneDrive-UniversityofWaterloo/Side Projects/object-detector/obj-detector/lib/python3.12/site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /Users/bks/Library/CloudStorage/OneDrive-UniversityofWaterloo/Side Projects/object-detector/obj-detector/lib/python3.12/site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in /Users/bks/Library/CloudStorage/OneDrive-UniversityofWaterloo/Side Projects/object-detector/obj-detector/lib/python3.12/site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (3.10.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /Users/bks/Library/CloudStorage/OneDrive-UniversityofWaterloo/Side Projects/object-detector/obj-detector/lib/python3.12/site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (16.0.6)\n",
      "Requirement already satisfied: ml-dtypes~=0.3.1 in /Users/bks/Library/CloudStorage/OneDrive-UniversityofWaterloo/Side Projects/object-detector/obj-detector/lib/python3.12/site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (0.3.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Users/bks/Library/CloudStorage/OneDrive-UniversityofWaterloo/Side Projects/object-detector/obj-detector/lib/python3.12/site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (3.3.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /Users/bks/Library/CloudStorage/OneDrive-UniversityofWaterloo/Side Projects/object-detector/obj-detector/lib/python3.12/site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (4.25.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/bks/Library/CloudStorage/OneDrive-UniversityofWaterloo/Side Projects/object-detector/obj-detector/lib/python3.12/site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (2.31.0)\n",
      "Requirement already satisfied: setuptools in /Users/bks/Library/CloudStorage/OneDrive-UniversityofWaterloo/Side Projects/object-detector/obj-detector/lib/python3.12/site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (69.1.1)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Users/bks/Library/CloudStorage/OneDrive-UniversityofWaterloo/Side Projects/object-detector/obj-detector/lib/python3.12/site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /Users/bks/Library/CloudStorage/OneDrive-UniversityofWaterloo/Side Projects/object-detector/obj-detector/lib/python3.12/site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (4.10.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /Users/bks/Library/CloudStorage/OneDrive-UniversityofWaterloo/Side Projects/object-detector/obj-detector/lib/python3.12/site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Users/bks/Library/CloudStorage/OneDrive-UniversityofWaterloo/Side Projects/object-detector/obj-detector/lib/python3.12/site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (1.62.1)\n",
      "Requirement already satisfied: tensorboard<2.17,>=2.16 in /Users/bks/Library/CloudStorage/OneDrive-UniversityofWaterloo/Side Projects/object-detector/obj-detector/lib/python3.12/site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (2.16.2)\n",
      "Requirement already satisfied: keras>=3.0.0 in /Users/bks/Library/CloudStorage/OneDrive-UniversityofWaterloo/Side Projects/object-detector/obj-detector/lib/python3.12/site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (3.0.5)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.26.0 in /Users/bks/Library/CloudStorage/OneDrive-UniversityofWaterloo/Side Projects/object-detector/obj-detector/lib/python3.12/site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (1.26.4)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Users/bks/Library/CloudStorage/OneDrive-UniversityofWaterloo/Side Projects/object-detector/obj-detector/lib/python3.12/site-packages (from astunparse>=1.6.0->tensorflow<3,>=2.1.0->tensorflowjs) (0.42.0)\n",
      "Requirement already satisfied: rich in /Users/bks/Library/CloudStorage/OneDrive-UniversityofWaterloo/Side Projects/object-detector/obj-detector/lib/python3.12/site-packages (from keras>=3.0.0->tensorflow<3,>=2.1.0->tensorflowjs) (13.7.1)\n",
      "Requirement already satisfied: namex in /Users/bks/Library/CloudStorage/OneDrive-UniversityofWaterloo/Side Projects/object-detector/obj-detector/lib/python3.12/site-packages (from keras>=3.0.0->tensorflow<3,>=2.1.0->tensorflowjs) (0.0.7)\n",
      "Requirement already satisfied: dm-tree in /Users/bks/Library/CloudStorage/OneDrive-UniversityofWaterloo/Side Projects/object-detector/obj-detector/lib/python3.12/site-packages (from keras>=3.0.0->tensorflow<3,>=2.1.0->tensorflowjs) (0.1.8)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/bks/Library/CloudStorage/OneDrive-UniversityofWaterloo/Side Projects/object-detector/obj-detector/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow<3,>=2.1.0->tensorflowjs) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/bks/Library/CloudStorage/OneDrive-UniversityofWaterloo/Side Projects/object-detector/obj-detector/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow<3,>=2.1.0->tensorflowjs) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/bks/Library/CloudStorage/OneDrive-UniversityofWaterloo/Side Projects/object-detector/obj-detector/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow<3,>=2.1.0->tensorflowjs) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/bks/Library/CloudStorage/OneDrive-UniversityofWaterloo/Side Projects/object-detector/obj-detector/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow<3,>=2.1.0->tensorflowjs) (2024.2.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/bks/Library/CloudStorage/OneDrive-UniversityofWaterloo/Side Projects/object-detector/obj-detector/lib/python3.12/site-packages (from tensorboard<2.17,>=2.16->tensorflow<3,>=2.1.0->tensorflowjs) (3.5.2)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /Users/bks/Library/CloudStorage/OneDrive-UniversityofWaterloo/Side Projects/object-detector/obj-detector/lib/python3.12/site-packages (from tensorboard<2.17,>=2.16->tensorflow<3,>=2.1.0->tensorflowjs) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Users/bks/Library/CloudStorage/OneDrive-UniversityofWaterloo/Side Projects/object-detector/obj-detector/lib/python3.12/site-packages (from tensorboard<2.17,>=2.16->tensorflow<3,>=2.1.0->tensorflowjs) (3.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Users/bks/Library/CloudStorage/OneDrive-UniversityofWaterloo/Side Projects/object-detector/obj-detector/lib/python3.12/site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow<3,>=2.1.0->tensorflowjs) (2.1.5)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/bks/Library/CloudStorage/OneDrive-UniversityofWaterloo/Side Projects/object-detector/obj-detector/lib/python3.12/site-packages (from rich->keras>=3.0.0->tensorflow<3,>=2.1.0->tensorflowjs) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/bks/Library/CloudStorage/OneDrive-UniversityofWaterloo/Side Projects/object-detector/obj-detector/lib/python3.12/site-packages (from rich->keras>=3.0.0->tensorflow<3,>=2.1.0->tensorflowjs) (2.17.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/bks/Library/CloudStorage/OneDrive-UniversityofWaterloo/Side Projects/object-detector/obj-detector/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow<3,>=2.1.0->tensorflowjs) (0.1.2)\n",
      "tensorflowjs_converter --input_format=tf_saved_model --output_node_names='detection_boxes,detection_classes,detection_features,detection_multiclass_scores,detection_scores,num_detections,raw_detection_boxes,raw_detection_scores' --output_format=tfjs_graph_model --signature_name=serving_default Tensorflow/assets/models/my_ssd_resnet50/export/saved_model Tensorflow/assets/models/my_ssd_resnet50/tfjsexport\n",
      "/Users/bks/Library/CloudStorage/OneDrive-UniversityofWaterloo/Side Projects/object-detector/obj-detector/lib/python3.12/site-packages/tensorflowjs/read_weights.py:28: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n",
      "  np.uint8, np.uint16, np.object, np.bool]\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/bks/Library/CloudStorage/OneDrive-UniversityofWaterloo/Side Projects/object-detector/obj-detector/bin/tensorflowjs_converter\", line 7, in <module>\n",
      "    from tensorflowjs.converters.converter import pip_main\n",
      "  File \"/Users/bks/Library/CloudStorage/OneDrive-UniversityofWaterloo/Side Projects/object-detector/obj-detector/lib/python3.12/site-packages/tensorflowjs/__init__.py\", line 21, in <module>\n",
      "    from tensorflowjs import converters\n",
      "  File \"/Users/bks/Library/CloudStorage/OneDrive-UniversityofWaterloo/Side Projects/object-detector/obj-detector/lib/python3.12/site-packages/tensorflowjs/converters/__init__.py\", line 21, in <module>\n",
      "    from tensorflowjs.converters.converter import convert\n",
      "  File \"/Users/bks/Library/CloudStorage/OneDrive-UniversityofWaterloo/Side Projects/object-detector/obj-detector/lib/python3.12/site-packages/tensorflowjs/converters/converter.py\", line 35, in <module>\n",
      "    from tensorflowjs.converters import keras_h5_conversion as conversion\n",
      "  File \"/Users/bks/Library/CloudStorage/OneDrive-UniversityofWaterloo/Side Projects/object-detector/obj-detector/lib/python3.12/site-packages/tensorflowjs/converters/keras_h5_conversion.py\", line 33, in <module>\n",
      "    from tensorflowjs import write_weights  # pylint: disable=import-error\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/bks/Library/CloudStorage/OneDrive-UniversityofWaterloo/Side Projects/object-detector/obj-detector/lib/python3.12/site-packages/tensorflowjs/write_weights.py\", line 25, in <module>\n",
      "    from tensorflowjs import read_weights\n",
      "  File \"/Users/bks/Library/CloudStorage/OneDrive-UniversityofWaterloo/Side Projects/object-detector/obj-detector/lib/python3.12/site-packages/tensorflowjs/read_weights.py\", line 28, in <module>\n",
      "    np.uint8, np.uint16, np.object, np.bool]\n",
      "                         ^^^^^^^^^\n",
      "  File \"/Users/bks/Library/CloudStorage/OneDrive-UniversityofWaterloo/Side Projects/object-detector/obj-detector/lib/python3.12/site-packages/numpy/__init__.py\", line 324, in __getattr__\n",
      "    raise AttributeError(__former_attrs__[attr])\n",
      "AttributeError: module 'numpy' has no attribute 'object'.\n",
      "`np.object` was a deprecated alias for the builtin `object`. To avoid this error in existing code, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
      "The aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n",
      "    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations. Did you mean: 'object_'?\n"
     ]
    }
   ],
   "source": [
    "# for use in web applications\n",
    "!pip3 install tensorflowjs\n",
    "command = \"tensorflowjs_converter --input_format=tf_saved_model --output_node_names='detection_boxes,detection_classes,detection_features,detection_multiclass_scores,detection_scores,num_detections,raw_detection_boxes,raw_detection_scores' --output_format=tfjs_graph_model --signature_name=serving_default {} {}\".format(os.path.join(paths['OUTPUT_PATH'], 'saved_model'), paths['TFJS_PATH'])\n",
    "print(command)\n",
    "!{command}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "obj-detector",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
